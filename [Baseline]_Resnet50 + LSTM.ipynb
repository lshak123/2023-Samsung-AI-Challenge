{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7691610e-65b8-4955-8a4d-27fca9b76373",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb06abd-6a59-4298-976d-f2cd487e9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26806a2c-9755-45f2-b945-4cdc26dc4165",
   "metadata": {},
   "source": [
    "## Hyperparameter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaffb268-9a47-45da-942b-f6b60b52b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS': 10, #Your Epochs,\n",
    "    'LR':0.01, #Your Learning Rate,\n",
    "    'BATCH_SIZE': 16, #Your Batch Size,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0fbf6-43b7-4d09-81da-149147f5fa44",
   "metadata": {},
   "source": [
    "## Fixed Random-Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0e6a64-4f23-4813-9426-e0b56ce797ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae6476-b1cc-434b-8f86-5149a283858d",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd25d3e2-f7c5-4f05-b6b0-d90f825b975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # mos column 존재 여부에 따라 값을 설정\n",
    "        mos = float(self.dataframe.iloc[idx]['mos']) if 'mos' in self.dataframe.columns else 0.0\n",
    "        comment = self.dataframe.iloc[idx]['comments'] if 'comments' in self.dataframe.columns else \"\"\n",
    "        \n",
    "        return img, mos, comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb969079-ac51-4a58-a7ac-20d27486022a",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a601035f-45f0-4855-97a3-b58cf408a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        # Image feature extraction using ResNet50\n",
    "        self.cnn_backbone = models.resnet50(pretrained=True)\n",
    "        # Remove the last fully connected layer to get features\n",
    "        modules = list(self.cnn_backbone.children())[:-1]\n",
    "        self.cnn = nn.Sequential(*modules)\n",
    "\n",
    "        # Image quality assessment head\n",
    "        self.regression_head = nn.Linear(2048, 1)  # ResNet50 last layer has 2048 features\n",
    "\n",
    "        # Captioning head\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim + 2048, hidden_dim)  # Image features and caption embeddings as input\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, images, captions=None):\n",
    "        # CNN\n",
    "        features = self.cnn(images)\n",
    "        features_flat = features.view(features.size(0), -1)\n",
    "\n",
    "        # Image quality regression\n",
    "        mos = self.regression_head(features_flat)\n",
    "\n",
    "        # LSTM captioning\n",
    "        if captions is not None:\n",
    "            embeddings = self.embedding(captions)\n",
    "            # Concatenate image features and embeddings for each word in the captions\n",
    "            combined = torch.cat([features_flat.unsqueeze(1).repeat(1, embeddings.size(1), 1), embeddings], dim=2)\n",
    "            lstm_out, _ = self.lstm(combined)\n",
    "            outputs = self.fc(lstm_out)\n",
    "            return mos, outputs\n",
    "        else:\n",
    "            return mos, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbbfc72-534d-46d7-b63e-56d28a43b04e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba3cae5-7482-4950-840f-4c6eb3700f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train_data = pd.read_csv('../open/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dca4e3-b554-4b8d-ad65-7e61bd35735e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "      <th>mos</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41wy7upxzl</td>\n",
       "      <td>../open/train/41wy7upxzl.jpg</td>\n",
       "      <td>5.569231</td>\n",
       "      <td>the pink and blue really compliment each other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ygujjq6xxt</td>\n",
       "      <td>../open/train/ygujjq6xxt.jpg</td>\n",
       "      <td>6.103175</td>\n",
       "      <td>love rhubarb! great colors!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wk321130q0</td>\n",
       "      <td>../open/train/wk321130q0.jpg</td>\n",
       "      <td>5.541985</td>\n",
       "      <td>i enjoy the textures and grungy feel to this. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w50dp2zjpg</td>\n",
       "      <td>../open/train/w50dp2zjpg.jpg</td>\n",
       "      <td>6.234848</td>\n",
       "      <td>i like all the different colours in this pic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l7rqfxeuh0</td>\n",
       "      <td>../open/train/l7rqfxeuh0.jpg</td>\n",
       "      <td>5.190476</td>\n",
       "      <td>i love these critters, just wish he was a litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74563</th>\n",
       "      <td>zbevd0lyox</td>\n",
       "      <td>../open/train/zbevd0lyox.jpg</td>\n",
       "      <td>5.926108</td>\n",
       "      <td>perfect balance here, in this soft serene image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74564</th>\n",
       "      <td>w26yu6ee60</td>\n",
       "      <td>../open/train/w26yu6ee60.jpg</td>\n",
       "      <td>5.966346</td>\n",
       "      <td>very nice indeed. the sharpness and contrast a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74565</th>\n",
       "      <td>a1pts9zzdx</td>\n",
       "      <td>../open/train/a1pts9zzdx.jpg</td>\n",
       "      <td>5.718447</td>\n",
       "      <td>nice tones and color for balance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74566</th>\n",
       "      <td>pzbubeo03l</td>\n",
       "      <td>../open/train/pzbubeo03l.jpg</td>\n",
       "      <td>6.007843</td>\n",
       "      <td>i like the bold colors. nice sharp image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74567</th>\n",
       "      <td>8c0klk5ule</td>\n",
       "      <td>../open/train/8c0klk5ule.jpg</td>\n",
       "      <td>5.599206</td>\n",
       "      <td>i am an aries and just flat out liked this ide...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74568 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_name                      img_path       mos  \\\n",
       "0      41wy7upxzl  ../open/train/41wy7upxzl.jpg  5.569231   \n",
       "1      ygujjq6xxt  ../open/train/ygujjq6xxt.jpg  6.103175   \n",
       "2      wk321130q0  ../open/train/wk321130q0.jpg  5.541985   \n",
       "3      w50dp2zjpg  ../open/train/w50dp2zjpg.jpg  6.234848   \n",
       "4      l7rqfxeuh0  ../open/train/l7rqfxeuh0.jpg  5.190476   \n",
       "...           ...                           ...       ...   \n",
       "74563  zbevd0lyox  ../open/train/zbevd0lyox.jpg  5.926108   \n",
       "74564  w26yu6ee60  ../open/train/w26yu6ee60.jpg  5.966346   \n",
       "74565  a1pts9zzdx  ../open/train/a1pts9zzdx.jpg  5.718447   \n",
       "74566  pzbubeo03l  ../open/train/pzbubeo03l.jpg  6.007843   \n",
       "74567  8c0klk5ule  ../open/train/8c0klk5ule.jpg  5.599206   \n",
       "\n",
       "                                                comments  \n",
       "0      the pink and blue really compliment each other...  \n",
       "1                            love rhubarb! great colors!  \n",
       "2      i enjoy the textures and grungy feel to this. ...  \n",
       "3      i like all the different colours in this pic, ...  \n",
       "4      i love these critters, just wish he was a litt...  \n",
       "...                                                  ...  \n",
       "74563   perfect balance here, in this soft serene image.  \n",
       "74564  very nice indeed. the sharpness and contrast a...  \n",
       "74565                  nice tones and color for balance.  \n",
       "74566          i like the bold colors. nice sharp image.  \n",
       "74567  i am an aries and just flat out liked this ide...  \n",
       "\n",
       "[74568 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['img_path'] = train_data['img_path'].apply(lambda x: x.replace('./','../open/'))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef63165-3e79-4a01-9f04-748f79c6db64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|█▎                                                          | 99/4661 [00:35<26:57,  2.82it/s, loss=4.22]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 45\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     48\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py:364\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    363\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 364\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    367\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 단어 사전 생성\n",
    "all_comments = ' '.join(train_data['comments']).split()\n",
    "vocab = set(all_comments)\n",
    "vocab = ['<PAD>', '<SOS>', '<EOS>'] + list(vocab)\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset = CustomDataset(train_data, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "# 모델, 손실함수, 옵티마이저\n",
    "model = BaseModel(len(vocab)).cuda()\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])\n",
    "\n",
    "# 학습\n",
    "model.train()\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for imgs, mos, comments in loop:\n",
    "        imgs, mos = imgs.float().cuda(), mos.float().cuda()\n",
    "        \n",
    "        # Batch Preprocessing\n",
    "        comments_tensor = torch.zeros((len(comments), len(max(comments, key=len)))).long().cuda()\n",
    "        for i, comment in enumerate(comments):\n",
    "            tokenized = ['<SOS>'] + comment.split() + ['<EOS>']\n",
    "            comments_tensor[i, :len(tokenized)] = torch.tensor([word2idx[word] for word in tokenized])\n",
    "\n",
    "        # Forward & Loss\n",
    "        predicted_mos, predicted_comments = model(imgs, comments_tensor)\n",
    "        loss1 = criterion1(predicted_mos.squeeze(1), mos)\n",
    "        loss2 = criterion2(predicted_comments.view(-1, len(vocab)), comments_tensor.view(-1))\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_description(f\"Epoch {epoch + 1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} finished with average loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864072e8-85dc-435d-9198-5b9e1f61bd24",
   "metadata": {},
   "source": [
    "## Inference & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b8d8b9-5833-48a9-8892-25c314e6c97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../open/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428452bd-2ca3-4c21-9075-1eecdf35bd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j00zs3u6dr</td>\n",
       "      <td>../open/test/j00zs3u6dr.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ytv70so3zb</td>\n",
       "      <td>../open/test/ytv70so3zb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ia9890oozp</td>\n",
       "      <td>../open/test/ia9890oozp.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xsj81ypx4a</td>\n",
       "      <td>../open/test/xsj81ypx4a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f23994ghlh</td>\n",
       "      <td>../open/test/f23994ghlh.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>ya8k1hklrg</td>\n",
       "      <td>../open/test/ya8k1hklrg.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>j59djzkvpj</td>\n",
       "      <td>../open/test/j59djzkvpj.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13009</th>\n",
       "      <td>o6w8lkfdy0</td>\n",
       "      <td>../open/test/o6w8lkfdy0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13010</th>\n",
       "      <td>hq68sz9xf5</td>\n",
       "      <td>../open/test/hq68sz9xf5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>7yq897iaoo</td>\n",
       "      <td>../open/test/7yq897iaoo.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_name                     img_path\n",
       "0      j00zs3u6dr  ../open/test/j00zs3u6dr.jpg\n",
       "1      ytv70so3zb  ../open/test/ytv70so3zb.jpg\n",
       "2      ia9890oozp  ../open/test/ia9890oozp.jpg\n",
       "3      xsj81ypx4a  ../open/test/xsj81ypx4a.jpg\n",
       "4      f23994ghlh  ../open/test/f23994ghlh.jpg\n",
       "...           ...                          ...\n",
       "13007  ya8k1hklrg  ../open/test/ya8k1hklrg.jpg\n",
       "13008  j59djzkvpj  ../open/test/j59djzkvpj.jpg\n",
       "13009  o6w8lkfdy0  ../open/test/o6w8lkfdy0.jpg\n",
       "13010  hq68sz9xf5  ../open/test/hq68sz9xf5.jpg\n",
       "13011  7yq897iaoo  ../open/test/7yq897iaoo.jpg\n",
       "\n",
       "[13012 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['img_path'] = test_data['img_path'].apply(lambda x: x.replace('./','../open/'))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa02d3b-6996-423e-aad2-6e6bb1b005bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_data, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "predicted_mos_list = []\n",
    "predicted_comments_list = []\n",
    "\n",
    "def greedy_decode(model, image, max_length=50):\n",
    "    image = image.unsqueeze(0).cuda()\n",
    "    mos, _ = model(image)\n",
    "    output_sentence = []\n",
    "    \n",
    "    # 시작 토큰 설정\n",
    "    current_token = torch.tensor([word2idx['<SOS>']]).cuda()\n",
    "    hidden = None\n",
    "    features = model.cnn(image).view(image.size(0), -1)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        embeddings = model.embedding(current_token).unsqueeze(0)\n",
    "        combined = torch.cat([features.unsqueeze(1), embeddings], dim=2)\n",
    "        out, hidden = model.lstm(combined, hidden)\n",
    "        \n",
    "        output = model.fc(out.squeeze(0))\n",
    "        _, current_token = torch.max(output, dim=1)\n",
    "\n",
    "        # <EOS> 토큰에 도달하면 멈춤\n",
    "        if current_token.item() == word2idx['<EOS>']:\n",
    "            break\n",
    "\n",
    "        # <SOS> 또는 <PAD> 토큰은 생성한 캡션에 추가하지 않음\n",
    "        if current_token.item() not in [word2idx['<SOS>'], word2idx['<PAD>']]:\n",
    "            output_sentence.append(idx2word[current_token.item()])\n",
    "     \n",
    "    return mos.item(), ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131ceac7-312c-4ea2-9988-e944678fec9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 407/407 [12:35<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# 추론 과정\n",
    "with torch.no_grad():\n",
    "    for imgs, _, _ in tqdm(test_loader):\n",
    "        for img in imgs:\n",
    "            img = img.float().cuda()\n",
    "            mos, caption = greedy_decode(model, img)\n",
    "            predicted_mos_list.append(mos)\n",
    "            predicted_comments_list.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab44cc7-1572-405e-a7a4-84b04178bacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "result_df = pd.DataFrame({\n",
    "    'img_name': test_data['img_name'],\n",
    "    'mos': predicted_mos_list,\n",
    "    'comments': predicted_comments_list  # 캡션 부분은 위에서 생성한 것을 사용\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b4e0167-bc39-4039-8625-4d9530acb6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 예측 결과에 NaN이 있다면, 제출 시 오류가 발생하므로 후처리 진행 (sample_submission.csv과 동일하게)\n",
    "result_df['comments'] = None\n",
    "result_df['comments'] = result_df['comments'].fillna('Nice Image.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617c46d0-58a0-4fbb-a7be-53ca7bb71c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>mos</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j00zs3u6dr</td>\n",
       "      <td>5.969956</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ytv70so3zb</td>\n",
       "      <td>5.861434</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ia9890oozp</td>\n",
       "      <td>5.440264</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xsj81ypx4a</td>\n",
       "      <td>5.581383</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f23994ghlh</td>\n",
       "      <td>5.119411</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>ya8k1hklrg</td>\n",
       "      <td>4.847887</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13008</th>\n",
       "      <td>j59djzkvpj</td>\n",
       "      <td>5.445950</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13009</th>\n",
       "      <td>o6w8lkfdy0</td>\n",
       "      <td>5.242831</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13010</th>\n",
       "      <td>hq68sz9xf5</td>\n",
       "      <td>6.246761</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>7yq897iaoo</td>\n",
       "      <td>5.460837</td>\n",
       "      <td>Nice Image.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13012 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_name       mos     comments\n",
       "0      j00zs3u6dr  5.969956  Nice Image.\n",
       "1      ytv70so3zb  5.861434  Nice Image.\n",
       "2      ia9890oozp  5.440264  Nice Image.\n",
       "3      xsj81ypx4a  5.581383  Nice Image.\n",
       "4      f23994ghlh  5.119411  Nice Image.\n",
       "...           ...       ...          ...\n",
       "13007  ya8k1hklrg  4.847887  Nice Image.\n",
       "13008  j59djzkvpj  5.445950  Nice Image.\n",
       "13009  o6w8lkfdy0  5.242831  Nice Image.\n",
       "13010  hq68sz9xf5  6.246761  Nice Image.\n",
       "13011  7yq897iaoo  5.460837  Nice Image.\n",
       "\n",
       "[13012 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e6a7226-362c-45f4-95c4-4336c78ccf66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed and results saved to submit.csv.\n"
     ]
    }
   ],
   "source": [
    "result_df.to_csv('../Sub/submit_base.csv', index=False)\n",
    "\n",
    "print(\"Inference completed and results saved to submit.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb35b0-47e4-4957-ab8b-ff5628cc023a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
